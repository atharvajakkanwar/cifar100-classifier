{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR100 Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook gives an overview of training an image classifier for the CIFAR 100 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL ARCHITECTURE\n",
    "**C : Convolution  \n",
    "A : Activation  \n",
    "MP: MaxPooling  \n",
    "DO: Dropout  \n",
    "F: Faltten  \n",
    "D: Dense  \n",
    "CL: OutputClasses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG A (Intuition)\n",
    "A basic intuituion in deciding the sizes and layers was to gradually increase the number of filters at each layer and ultimately faltten the layers and give the output size as the number of classes that the dataset contains.  \n",
    "\n",
    "The last 0.3 part of the training data is used as validation data.\n",
    "\n",
    "**Architecture: C(32)->A->MP(2x2)->C(64)->A->MP(2x2)->DO(0.1)->C(128)->A->MP(2x2)>DO(0.25)->F->D(512)->A->DO(0.5)->CL(100)**   \n",
    "**Optimizer: SGD**  \n",
    "**Epochs: 30**  \n",
    "**Batchsize: 100**  \n",
    "**Loss(validation): 3.2751% Accuracy(validation): 0.2207**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](g1.JPG)\n",
    "Fig1. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration had a large batch size which resulted in faster progress in training, but does not always guarantee fast convergence which can be seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG B (Batch and Epoch changes)\n",
    "  \n",
    "The batch size was reduced and the number of epochs increased.  \n",
    "\n",
    "**Architecture: C->MP->C->MP->DO->C->MP>DO->F->D->DO->CL**  \n",
    "**Dropouts: 0.1 -> 0.25 -> 0.5**  \n",
    "**Optimizer: SGD**  \n",
    "**Epochs: 50**  \n",
    "**Batchsize: 50**  \n",
    "**Loss(validation): 2.397% Accuracy(validation): 0.3981**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](g2.JPG)\n",
    "Fig2. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change in number of epochs and batch size resulted in improved accuracy. It can be seen that the accuracy was still increasing and had not yet reached a plateau, so the number of epochs have to be increased further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG C (Adam Optimizer and increased epochs)\n",
    "Number of epochs were increased and the the otimizer was changed to Adam to test if it gives better convergence.    \n",
    "\n",
    "**Architecture: C->MP->C->MP->DO->C->MP>DO->F->D->DO->CL**  \n",
    "**Dropouts: 0.1 -> 0.25 -> 0.5**  \n",
    "**Optimizer: Adam**  \n",
    "**Epochs: 100**  \n",
    "**Batchsize: 50**  \n",
    "**Loss(validation): 2.7191% Accuracy(training): 0.75 Accuracy(validation): 0.4309**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](g3.JPG)\n",
    "Fig3. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy is greatly improved due to the increased epochs. Validation losses erratic behaviour, sudednly increasing after hitting a minima even while the validation accuracy remains almost constant. This indicates that the model gets better at identifying the training data, but gets worse at classifying new data(validation), which inturn indicates that the model is overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG D  (Increased Dropouts to prevent overfitting)\n",
    "To prevent overfitting, we need to reduce the number of parameters. One way of doing this is by increasing the dropout rate. So the dropout rate is increased in all the layers to be 0.5. Epochs is reduced to save training time as the accuracy reaches a considerably stable percetage around 50 epochs.  \n",
    "\n",
    "**Architecture: C->MP->C->MP->DO->C->MP>DO->F->D->DO->CL**  \n",
    "**Dropouts: 0.5 -> 0.5 -> 0.5**  \n",
    "**Optimizer: Adam**  \n",
    "**Epochs: 50**  \n",
    "**Batchsize: 50** \n",
    "**Loss(validation): 2.4% Accuracy(validation): 0.425**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](g4.JPG)\n",
    "Fig4. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout infact reduced the problem of overfitting as can be seen in the validation losses. Increasing the number of epochs can possibly improve the accuracy even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation may also help in training a more generalised classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG E (ELU activation and Regularization)\n",
    "To try out other acitvation functions, I tried ELU. ELU is said to haveing improved learning characteristics [FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)](https://arxiv.org/pdf/1511.07289.pdf) for CIFAR100 without batch normalizations. I also introduced another stack of C->MP->DO layer. L2 regularization was used with 0.005 penalty.\n",
    "\n",
    "**Architecture: C(32)->A->MP(2x2)->C(64)->A->MP(2x2)->DO(0.5)->C(128)->A->MP(2x2)>DO(0.5)->C(128)->A->MP(2x2)->DO(0.5)->F->D(512)->A->DO(0.5)->CL(100)**  \n",
    "**Dropouts: 0.5 -> 0.5 -> 0.5**  \n",
    "**Optimizer: ELU**  \n",
    "**Epochs: 70**  \n",
    "**Batchsize: 50** \n",
    "**Loss(validation): 2.4% Accuracy(validation): 0.445**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](g5.JPG)\n",
    "Fig6. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ELU did not show drastic improvements. This could have been due to the different architecture as proposed in [FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)](https://arxiv.org/pdf/1511.07289.pdf). One change that was observed was significatly faster convergence, probably due to the presence of regularization. Each epoch took half the time it previouly took took complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG F (Removing Regularization from E)\n",
    "Removing regularization increased the processing time a bit but showed no significant change in the accuracy.\n",
    "![](g6.JPG)\n",
    "Fig7. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG G (Changing number of filters)\n",
    "Keeping all configurations same as in F, the number of filters were changed to 64->128->128->256->512\n",
    "![](g7.JPG)\n",
    "Fig7. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a slight improvement of about 4% and it seemed to increase steadily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG H\n",
    "Since CONFIG D showed the most promising results, I ran it for 80 epoccs this time and 0.15 validation split it showed consistent performance and a slight increase in performance with **0.4 training accuracy and 0.45 validation accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](g8.JPG)\n",
    "Fig8. (a)training accuracy (b)training loss(%) (c) validation_accuracy (d) validation_loss(%)  \n",
    "[all graphs have epochs as the x axis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PYTHON CODE (Keras with Tensorflow backend)\n",
    "\n",
    "Matplotlib libraries wont work on non GUI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Keras backend to follow dimension ordering as supported by Tensorflow.  \n",
    "Storing all the generated metrics in /Performance deirectory to be viewed in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "keras.backend.set_image_dim_ordering('tf')\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Performance', histogram_freq=0,\n",
    "                                         write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import cifar100 dataset provided in Keras.  \n",
    "Convert the data to _float32_ and normalise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "def import_data():\n",
    "    \"\"\"\n",
    "    Preprocess cifar100 data by normalising and converting it to float32.\n",
    "    Returns:\n",
    "        list\n",
    "            a list of training data and test data (x,y,x,y).\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "    print(\"Train data size: \" + str(x_train.shape[0]))\n",
    "    print(\"Test data size: \" + str(x_test.shape[0]))\n",
    "    y_train = keras.utils.to_categorical(y_train, 100)\n",
    "    y_test = keras.utils.to_categorical(y_test, 100)\n",
    "    # convert to float ndarray\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # normalize\n",
    "    x_train /= 255.\n",
    "    x_test /= 255.\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (CONFIG D/H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "def get_model(output_size, input_shape, opt, dropout = 0):\n",
    "    \"\"\"\n",
    "    Returns a model based on the given parameters and the underlying architecture.\n",
    "    Input:\n",
    "        output_size: the size of the output (the number of classe in this case)\n",
    "        input_shape: the shape of the input to the first conv layer\n",
    "        opt: the optimizer to be used\n",
    "        dropout: an integer flag representing wheter or not to use drop out. default at 0(false) \n",
    "    Returns:\n",
    "        A model with the above specifications and following architecture:\n",
    "        C->MP->C->MP->DO->C->MP>DO->F->D->DO->CL                \n",
    "    \"\"\"\n",
    "\n",
    "    C1 = Conv2D(32, (3, 3), padding='same',input_shape=input_shape)\n",
    "    MP1 = MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "    C3 = Conv2D(64, (3, 3), padding='same')\n",
    "    MP2 = MaxPooling2D(pool_size=(2, 2))\n",
    "    DO1 = Dropout(0.5)\n",
    "\n",
    "    C5 = Conv2D(128, (3, 3), padding='same')\n",
    "    MP3 = MaxPooling2D(pool_size=(2, 2))  \n",
    "    DO2 = Dropout(0.5)\n",
    "\n",
    "    F1 = Flatten()\n",
    "    D1 = Dense(512)\n",
    "    DO3 = Dropout(0.5)\n",
    "    \n",
    "    CL = Dense(output_size)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(C1)\n",
    "    model.add(MP1)\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(C3)\n",
    "    model.add(MP2)\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout !=0:\n",
    "        model.add(DO1)\n",
    "\n",
    "    model.add(C5)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MP3)\n",
    "    if dropout !=0:\n",
    "        model.add(DO2)    \n",
    "\n",
    "    model.add(F1)\n",
    "    model.add(D1)\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout !=0:\n",
    "        model.add(DO3)\n",
    "        \n",
    "    model.add(CL)\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = import_data()\n",
    "#training data\n",
    "x_train = data[0]\n",
    "y_train = data[1]\n",
    "#validation data\n",
    "val_data_x = data[0][35000:50000]\n",
    "val_data_y = data[1][35000:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_size = 100\n",
    "input_shape=data[0].shape[1:]\n",
    "# opt = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "loss='categorical_crossentropy'\n",
    "dropout = 0 #(0 for false 1 for true)\n",
    "\n",
    "my_model = get_model(output_size, input_shape, opt, dropout)\n",
    "my_model.compile(loss=loss,\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and save weights (Run this only for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 50\n",
    "# train model\n",
    "my_model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_split=0.3,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[tbCallBack])\n",
    "# save weights\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "my_model.save_weights('weightsfull.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate data without dropout layers\n",
    "The same model is compiled again without the droupout layers to check if the validation data yields the same accuracy results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropout = 0\n",
    "val_model = get_model(output_size, input_shape, opt, dropout)\n",
    "val_model.load_weights('weightsfull.h5')\n",
    "val_model.compile(loss=loss,\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])\n",
    "val_res = val_model.evaluate(val_data_x, val_data_y, batch_size=50, verbose=1)\n",
    "print(val_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The loss percentage for the validation data set comprising of the last 15000 elements of the training data is 2.21% and the accuracy is 43.5%. This was achieved with CONFIG D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "We will use the same model wihout the dropout layers for testing as dropout is introduced only to prevent overfitting while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data_x = data[2]\n",
    "test_data_y = data[3]\n",
    "test_res = val_model.evaluate(test_data_x, test_data_y, batch_size=50, verbose=1)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The loss percentage for the test data set comprising of the 10000 elements of the test data is 2.185% and the accuracy is 41.1%. This was achieved with CONFIG D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict test data\n",
    "test_results = []\n",
    "for i in range(len(test_data_x)):\n",
    "    test_results.append(val_model.predict(test_data_x[i:i+1], verbose=1))\n",
    "\n",
    "# select max value from the probablility vector of 100 classes\n",
    "pred = []\n",
    "flat_pred =[]\n",
    "for p in (test_results):\n",
    "    pred.append(p[0].argsort()[-1:][::-1])\n",
    "#flatten the list of list into a list\n",
    "for sublist in pred:\n",
    "    for item in sublist:\n",
    "        flat_pred.append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# actual labels\n",
    "act = []\n",
    "flat_act = []\n",
    "for a in test_data_y:\n",
    "    act.append(a.argsort()[-1:][::-1])\n",
    "#flatten the list of list into a listfor sublist in act:\n",
    "    for item in sublist:\n",
    "        flat_act.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "conf_mat = tf.contrib.metrics.confusion_matrix(np.asarray(flat_act, dtype=np.float32), np.asarray(flat_pred, dtype=np.float32), 100, dtype=np.float32)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the confusion matrix for CONFIG D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert tensor to numpy array for displaying\n",
    "to_print = tf.Session().run(conf_mat)\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plot\n",
    "mp.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "ax = plot.subplot(111)\n",
    "plot.imshow(np.asarray(to_print, dtype=np.float32))\n",
    "plot.xlabel('Predicted Fine Class', fontsize=16)\n",
    "plot.ylabel('Actual Fine Class', fontsize=16)\n",
    "\n",
    "plot.colorbar(fraction=0.046, pad=0.04)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](conf.JPG)\n",
    "Fig5. The confusion matrix created by predicting the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix represents a 100x100 matrix of the predictions vs the actual label for the test data. Each cell in the diagonal represents the correct number of predcitions. The total number of correct predictions for a class go into the actual row for that class value and the predicted column for that class value. The brighter color represents higher value which indicates higher correct predictions. This indicates that the classifier is performing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on images outside the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# http://corochann.com/cifar-10-cifar-100-dataset-introduction-1258.html\n",
    "CIFAR100_LABELS_LIST = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict external image\n",
    "Testing with data from outside the CIFAR100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PIL2array(img):\n",
    "    return np.array(img.getdata(),\n",
    "                    np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "\n",
    "def predict_custom_image(label, path):\n",
    "    \"\"\"\n",
    "    Predicts the CIFAR100 class of a given 32X32 image\n",
    "    Input:\n",
    "        lable: label for the input image (should be from CIFAR fine labels)\n",
    "        path: path of the input image        \n",
    "    \"\"\"\n",
    "    # plot the image\n",
    "    from PIL import Image\n",
    "    img_ori =Image.open(path)\n",
    "    import matplotlib as mp\n",
    "    import matplotlib.pyplot as plot\n",
    "    mp.rcParams['figure.figsize'] = (6,6)\n",
    "    \n",
    "    # process\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((32,32), Image.ANTIALIAS)\n",
    "     \n",
    "    ax = plot.subplot(111)\n",
    "    plot.imshow(img_ori)\n",
    "#     ax = plot.subplot(122)\n",
    "#     plot.imshow(img)\n",
    "    plot.show()\n",
    "\n",
    "    img = np.array(img)\n",
    "    img = np.asarray([img])\n",
    "    predicted = val_model.predict(img)[0].argsort()[-5:][::-1]\n",
    "\n",
    "    print(\"Actual: \",  label)\n",
    "    print(\"Predicted: \" ,predicted[0], CIFAR100_LABELS_LIST[predicted[0]]) \n",
    "    print(\"Next 4:\",\n",
    "          CIFAR100_LABELS_LIST[predicted[1]], \n",
    "          CIFAR100_LABELS_LIST[predicted[2]], \n",
    "          CIFAR100_LABELS_LIST[predicted[3]],\n",
    "         CIFAR100_LABELS_LIST[predicted[4]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_custom_image(\"motorcycle\", 'motor.JPG') \n",
    "predict_custom_image(\"lobster\", 'lobster.JPG') ## Predicts orchid based on the shape of the petals\n",
    "predict_custom_image(\"orchid\", 'orchid.JPG') \n",
    "predict_custom_image(\"rose\", 'rose.JPG')  \n",
    "predict_custom_image(\"girl\", 'dany.JPG') ## Predicted keyboard using the checkered pattern on the walls\n",
    "predict_custom_image(\"house\", 'house.JPG') \n",
    "predict_custom_image(\"rose\", 'black_rose.JPG') ## Predicted as telephone, uses color to predict rose, hence cannot identify it\n",
    "predict_custom_image(\"girl\", 'arya.JPG') ## Always confuses arya for orchids!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict images from CIFAR test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_cifar_img(im_num):\n",
    "    \"\"\"\n",
    "    Predicts the given image number from CIFAR100 data set\n",
    "    \"\"\"\n",
    "    # extract the image\n",
    "    img = test_data_x[im_num]\n",
    "    # extract the image label\n",
    "    actual = test_data_y[im_num].argsort()[-1:][::-1]\n",
    "    # plot the image\n",
    "    import matplotlib as mp\n",
    "    import matplotlib.pyplot as plot\n",
    "    mp.rcParams['figure.figsize'] = (3,3)\n",
    "    ax = plot.subplot(111)\n",
    "    plot.imshow(img)\n",
    "    plot.show()\n",
    "\n",
    "\n",
    "    img = np.asarray([img])\n",
    "    predicted = val_model.predict(img)[0].argsort()[-1:][::-1]\n",
    "\n",
    "    print(\"Image number: \", im_num)\n",
    "    print(\"Predicted class:\" ,predicted[0], CIFAR100_LABELS_LIST[predicted[0]])\n",
    "    print(\"Actual class:\", actual[0],  CIFAR100_LABELS_LIST[actual[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting random images from CIFAR100 test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_random_cifar(num_img, random, skip):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        num_img: number of images to predict\n",
    "        random: a random number to select random images\n",
    "        skip: another random number \n",
    "    Precondition:\n",
    "        num_img*random+skip < 10000\n",
    "    \"\"\"\n",
    "    import matplotlib as mp\n",
    "    import matplotlib.pyplot as plot\n",
    "    # print the images and predictions\n",
    "    for i in range(num_img):\n",
    "        # display original\n",
    "        ax = plot.subplot(1, num_img, i + 1)\n",
    "        predict_cifar_img(i*random+skip)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    # plot.tight_layout()\n",
    "    plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_random_cifar(5, 683, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pred_1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some false results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](false1.JPG) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
